---
title: |
  <center> DATA 698 </center>
  <center> Capstone Project </center>
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document:
    toc: yes
    toc_depth: 4
---

\begin{center}
\bigskip
\bigskip
\bigskip
Prepared for:\\
\medskip
Prof. Dr. Nasrin Khansari\\
\smallskip
City University of New York, School of Professional Studies\\
\bigskip
Prepared by:\\
\medskip
Sie Siong Wong\\ 
\smallskip
Mario Pena\\
\smallskip
Joseph Shi\\  
\end{center}

\pagebreak

```{R message=FALSE, warning=FALSE, echo=FALSE}
options(warn=-1)
if(!require('tidyverse')) (install.packages('tidyverse'))
if(!require('academictwitteR')) (install.packages('academictwitteR'))
if(!require('tidyr')) (install.packages('tidyr'))
if(!require('readr')) (install.packages('readr'))
if(!require('dplyr')) (install.packages('dplyr'))
if(!require('zipcodeR')) (install.packages('zipcodeR'))
if(!require('RSocrata')) (install.packages('RSocrata'))
if(!require('future.apply')) (install.packages('future.apply'))
if(!require('syuzhet')) (install.packages('syuzhet'))
if(!require('tm')) (install.packages('tm'))
if(!require('lda')) (install.packages('lda'))
if(!require('anytime')) (install.packages('anytime'))
if(!require('SnowballC')) (install.packages('SnowballC'))
if(!require('topicmodels')) (install.packages('topicmodels'))
if(!require('wordcloud')) (install.packages('wordcloud'))
if(!require('tidytext')) (install.packages('tidytext'))
```

\newpage

# Abstract

\newpage

# Introduction

$$\\[0.5in]$$
![Architecture of the Proposed Methodology]("C:\\Users\\wongs34\\Documents\\School\\DATA 698\\Proposal\\Architecture of the Proposed Methodology.png")

\newpage

# Literature Review

([\textcolor{cyan}{Williams et al., 2019}](https://academic.oup.com/bjc/article/60/1/93/5537169)) A similar research was conducted to analyze association between online hate speech and offline racism and religion related crimes that occurred in London. A Weka tool was used to develop a machine learning classifier to annotate racism and religion and non-hateful tweets. Besides tweets and crime data, census data such as no qualifications, age, long-term unemployed, and black and minority ethnicity, were considered part of the study. Statistical models were built to study a temporal and spatial association. Random and fixed effects, Poisson regression models, and negative binomial models, which all results show consistent of positive association between hate speech in Twitter and offline racially and religiously discriminated crimes. Other research has also shown that online hate speech has a strong correlation with significant events such as terror attacks, political votes, etc ([\textcolor{cyan}{Hanes \& Machin, 2013}](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1038.9462&rep=rep1&type=pdf); [\textcolor{cyan}{Williams \& Burnap, 2015}](https://academic.oup.com/bjc/article/56/2/211/2462519)). A recent example of this was the Christchurch extreme right terror attacker’s post on 8chan. Although there is no direct causal link between online hate speech and offline hate crime, hate speech is still part of the cumulative process for a hate formula from social status, political context and geographical perspective that bring harm to the physical world. 

Nowadays, hate speech detection remains a big challenge for artificial intelligence. ([\textcolor{cyan}{Matsaki L., 2018}](https://www.wired.com/story/break-hate-speech-algorithm-try-love/)) Because the definition of hate speech is constantly evolving and often hidden within context, AI can be fooled easily. AI can be fooled by inserting typos, adding extra alphabets, and removing spaces. An example of altered text to evade AI detection would be something like this: “MartiansAreDisgustingAndShouldBeKilled love.” Humans can understand this message but the machine learning algorithms have trouble identifying it. Facebook CEO Mark Zuckerberg testified before congress in 2018 and mentioned he was optimistic that in 10 years AI would be able to identify hate speech more accurate. ([\textcolor{cyan}{Shead S., 2020}](https://www.cnbc.com/2020/11/19/facebook-says-ai-detects-94point7percent-of-hate-speech-removed-from-platform.html#:~:text=Facebook%20announced%20Thursday%20that%20artificial,and%20just%2024%25%20in%202017)) Only 24 percent of hate speech was able to be detected according to Facebook’s chief technology officer, Mike Schroepfer. Billions of users consume the Facebook product and platform, a cutting-edge machine technology to accurately spot hate speech is a must-have, to protect its users from exposure to harmful content. 

Many previous researchers have tried different machine learning approaches to best identify hate speech. ([\textcolor{cyan}{Lee et al., 2022}](https://www.researchgate.net/publication/357916429_Racism_Detection_by_Analyzing_Differential_Opinions_Through_Sentiment_Analysis_of_Tweets_Using_Stacked_Ensemble_GCR-NN_Model)) Stacked ensemble Gated Convolutional Recurrent- Neural Networks (GCR-NN), a deep learning approach was used to detect racist speech from a tweets dataset. Its 0.98 accuracy outperforms other conventional machine learning models such as Random Forest, K-Nearest Neighbors, SVM, etc. A large scale dataset of tweets related to racism from the world were collected, preprocessed to such detail as to remove stop words, annotated using the TextBlob into positive, negative and neutral score sentiments before performing Term Frequency - Inverse Document Frequency (TD-IDF), and Bag of Words (BoW) for machine learning models development. United States has the highest number of racist tweets, 50%, followed by United Kingdom, 31%. More than 53% of people age between 15-30 years old in the United States is exposed to online hate material ([\textcolor{cyan}{Hawdon et al., 2016}](https://www.researchgate.net/publication/303480309_Exposure_to_Online_Hate_in_Four_Nations_A_Cross-National_Consideration)). Both Logistic Regression and SVM performs better than other models using BoW features on average with a 0.97 accuracy score. For a fair comparison, few single deep learning models such as Gated Recurrent Unit (GRU), Long Short Term Memory (LSTM), Convolutional Neural Networks (CNN), and Recurrent Neural Networks (RNN), were also implemented and optimized through hyper parameter tuning. ([\textcolor{cyan}{Crabb et al., 2019}](https://towardsdatascience.com/classifying-hate-speech-an-overview-d307356b9eba); [\textcolor{cyan}{Starosta A., 2019}](https://medium.com/sculpt/a-technique-for-building-nlp-classifiers-efficiently-with-transfer-learning-and-weak-supervision-a8e2f21ca9c8)) Combination of Weak Supervision and Transfer Learning approach is useful for identifying which data lacks labeling. Weak supervision is a method for building a labeled training set from a large amount of unlabeled data. Transfer learning is a method where it reuses already existing pre-trained models for new tasks. It will use the training set created from weak supervision stage to build a new classifier model.

Research has found that there is a contradiction between freedom of speech and hate speech. Hate speech creates an environment that tests the limits of free speech, and it violates fundamental rights of a human being. On social networks, we can observe how other forms of violence such as terrorism, extremism and hate crimes, may each have their own space, victims and aggressors ([\textcolor{cyan}{Chetty \& Alathur, 2018}](https://www.sciencedirect.com/science/article/pii/S1359178917301064)). [\textcolor{cyan}{Miró-Llinares and Rodriguez-Sala (2016)}](https://www.researchgate.net/publication/308487177_Cyber_hate_speech_on_twitter_Analyzing_disruptive_events_from_social_media_to_build_a_violent_communication_and_hate_speech_taxonomy) describe the existence of many different types of hate speech that target different groups and individuals. Research has been done to differentiate and define each type accordingly. It is important to keep in mind classification as it will help us group Tweets with similar speech together in one category. Some of the approaches to the classification of hate speech from Tweeter used by [\textcolor{cyan}{Miró-Llinares and Rodriguez-Sala (2016)}](https://www.researchgate.net/publication/308487177_Cyber_hate_speech_on_twitter_Analyzing_disruptive_events_from_social_media_to_build_a_violent_communication_and_hate_speech_taxonomy) take into account the hashtags as a variable for predicting violence and hate message from the tweet. While some of their other approaches for classification of hate speech on social media also include the development of neural language models. It is also important to underline that the authors warn the development of classification algorithms may not allow for a deeper understanding of the different nature of violent communications. The recommendation they make is to pursue a thorough study of the categorization of different expressions that are evident in these types of messages.

The study conducted by [\textcolor{cyan}{Miró-Llinares et al. (2018)}](https://link.springer.com/article/10.1186/s40163-018-0089-1) focuses on designing an algorithm to detect hate speech in digital microenvironments. Its purpose is to facilitate and reduce analysis tasks undergone by law enforcement agencies and service providers. The algorithm used in this specific article uses machine learning classification techniques such as Random Forests. Furthermore, the study demonstrated that not all variables in the data relating to anonymity and visibility of users are applicable in distinguishing hate speech in tweets’ content, and that tweet metadata proved to be more efficient in the classification process than account metadata. Compared to similar studies that have applied different classification approaches, the results obtained by this study slightly outperform the others. The Random Forest model applied reached a F1-score of 0.92, highlighting the accuracy of the model on the dataset. Previous attempts from other studies have obtained F-measures of 0.77, 0.90 and 0.76 according to the literature in this specific study.

We have also found research that is centered on the idea that social media metadata is a valuable input in the analysis of opinions and sentiment. From activism to detecting road traffic, access to these data is essential in today’s comprehensive analyses. Using data from 18 Spanish-speaking Latin American countries, research found that similarly to mass media, social media suffers from a strong bias towards violent or sexual crimes. Simple models such as a linear regression were used in the research by [\textcolor{cyan}{Curiel et al. (2020)}](https://www.nature.com/articles/s41599-020-0430-7#Sec8) and found that countries with higher number of murders, murder rate and fear of crime are more likely to have crime-related tweets. However, it mainly represents the fears that people have of crime that may overemphasize certain types of crimes that are not as common as one would think. It was also found that there may not be a correlation at all between social media messages and crime, but rather demonstrate the reflection of the level of the fear of crime.

As explained by [\textcolor{cyan}{Chen et al. (2015)}](https://ieeexplore.ieee.org/abstract/document/7117012/authors#authors), it is possible for weather to also be used as a feature for modeling crime around Tweeter data. Their work is also focused on predicting crime in order to maximize the allocation of scarce police resources. Their paper noted the limitations of past studies, suggesting that weather is a significant factor and it has been proved there is a correlation between weather and criminal activity. It is thought that certain environmental factors such as weather, should be considered as it may affect the occurrence of criminal incidents. Such data containing information about theft density, Twitter data, weather and geolocation points, have been modeled using logistic regression with recommendations for future analysis using support vector machine ([\textcolor{cyan}{Chen et al., 2015}](https://ieeexplore.ieee.org/abstract/document/7117012/authors#authors)). More advanced techniques to predicting crime from Tweeter posts include Artificial Neural Networks approach that have achieved average accuracies of 0.903 on testing dataset and 0.933 on the training dataset as those demonstrated by [\textcolor{cyan}{Sandagiri et al. (2021)}](https://ieeexplore.ieee.org/document/9325485).

To develop and train a hate detection model, we’ll need a dataset with each record labeled with either hate or non-hate. This article ([\textcolor{cyan}{Alnazzawi, 2022}](https://www.mdpi.com/2306-5729/7/6/69)) developed a corpus which has hate related context, hate crime type, and the motivation behind the hate crime. This dataset is available in the [\textcolor{cyan}{Kaggle}](https://www.kaggle.com/datasets/nohaalnazzawi/the-hatemotiv-corpus) website and freely available to download. For our research, we could leverage this dataset in part of our annotation process to classify hate and non-hate tweets using the key words in the given hate related context. There were two steps in developing the dataset, corpus construction and annotation. The author used a Hashtag tracking tool [\textcolor{cyan}{“Hashtagify”}](https://hashtagify.me/) to search for hate related hashtags which were later to be used in the TweetsScraper tool to collect tweets related to hateful contents. Nine years (2010-2019) of tweets data related to these hashtags were collected. These hashtags list contain hate crime, racist, racism, Islamophobia, Islamophobic, sexism, disability, transgender, antisemitism, misogyny, and disabled. This hashtags list was found to be similar to what FBI used for the hate crime classification. For the annotation part, the author used the [\textcolor{cyan}{COGITO Tech (LLC)}](https://www.cogitotech.com/about-us) service to annotate each hate related tweets with 3 types of hate crime (physical assault, verbal abuse, incitement to hatred) and 5 types of motivation (racism, religion, disability, sexism, unknown) behind committing the crime. More than 60% of the 23,179 tweets, which hashtags’ are hate crime related, are made up of physical assault and most of these physical assault crimes were motivated because of different races and ethnicities.

\newpage

# Theory and Hypotheses

\newpage

# Data and Methods

\newpage

# Results

\newpage

# Discussion

\newpage

# Conclusion

\newpage

# References

1. Kshirsagar V. (2019, December 24). *Detecting Hate tweets — Twitter Sentiment Analysis*. Towards Data Science. Retrieved from https://towardsdatascience.com/detecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6

2. Crabb et al. (2019, May 28). *Classifying Hate Speech: an overview*. Towards Data Science. Retrieved from https://towardsdatascience.com/classifying-hate-speech-an-overview-d307356b9eba

3. Pang, G. (2022, March 4). *Deep Learning for Hate Speech Detection: A Large-scale Empirical Evaluation*. Towards Data Science. Retrieved from https://towardsdatascience.com/deep-learning-for-hate-speech-detection-a-large-scale-empirical-evaluation-92831ded6bb6

3. Kim, H. (2022). *Sentiment Analysis: Limits and Progress of the Syuzhet Package and Its Lexicons*. Texas A&M University. Retrieved from http://www.digitalhumanities.org/dhq/vol/16/2/000612/000612.html

4. Williams et al. (2019, July 23). *Hate in the Machine: Anti-Black and Anti-Muslim Social Media Posts as Predictors of Offline Racially and Religiously Aggravated Crime*. The British Journal of Criminology. Retrieved from https://academic.oup.com/bjc/article/60/1/93/5537169

5. Lee et al. (2022, January). *Racism Detection by Analyzing Differential Opinions Through Sentiment Analysis of Tweets Using Stacked Ensemble GCR-NN Model*. ResearchGate. Retrieved from https://www.researchgate.net/publication/357916429_Racism_Detection_by_Analyzing_Differential_Opinions_Through_Sentiment_Analysis_of_Tweets_Using_Stacked_Ensemble_GCR-NN_Model

6. Matsaki L. (2018, September 26). *To Break a Hate-Speech Detection Algorithm, Try 'Love'*. Wired.  Retrieved from https://www.wired.com/story/break-hate-speech-algorithm-try-love/

7. Rizwan et al. (2020, January). *Hate-Speech and Offensive Language Detection in Roman Urdu*. ACL Anthology. Retrieved from https://aclanthology.org/2020.emnlp-main.197.pdf

8. Miró-Llinares et al. (2018, November 15). *Hate is in the air! But where? Introducing an algorithm to detect hate speech in digital microenvironments*. Springer Link. Retrieved from https://link.springer.com/article/10.1186/s40163-018-0089-1

9. Curiel et al. (2020, April 02). *Crime and its fear in social media*. Nature. Retrieved from https://www.nature.com/articles/s41599-020-0430-7#Sec8

10. Sandagiri et al. (2021, January 19). *Detecting Crime Related Twitter Posts using Artificial Neural Networks based Approach*. IEEE Xplore. Retrieved from https://ieeexplore.ieee.org/document/9325485

11. Kumar, A. (2022, March 20). *Hate Speech Detection Using Machine Learning*. Vitalflux. Retrieved from https://vitalflux.com/hate-speech-detection-using-machine-learning/#:~:text=The%20techniques%20for%20detecting%20hate,to%20find%20patterns%20in%20data.

12. Alnazzawi, N. (2022, May 24). *Using Twitter to Detect Hate Crimes and Their Motivations: The HateMotiv Corpus*. MDPI. Retrieved from https://www.mdpi.com/2306-5729/7/6/69

13. Kocon et al. (2021, June 03). *Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach*. ScienceDirect. Retrieved from https://www.sciencedirect.com/science/article/pii/S0306457321001333

14. Shead, S. (2020, November 19). *Facebook claims A.I. now detects 94.7% of the hate speech that gets removed from its platform*. CNBC. Retrieved from https://www.cnbc.com/2020/11/19/facebook-says-ai-detects-94point7percent-of-hate-speech-removed-from-platform.html#:  
~:text=Facebook%20announced%20Thursday%20that%20artificial,and%20just%2024%25%20in%202017.

15. Williams, M. & Burnap, P. (2015, June 25 ). *Cyberhate on Social Media in the Aftermath of Woolwich: A Case Study in Computational Criminology and Big Data*. British Journal of Criminology. Retrieved from https://academic.oup.com/bjc/article/56/2/211/2462519

16. Hanes, E. & Machin, S. (2013, September). *Hate Crime in the Wake of Terror Attacks: Evidence from 7/7 and 9/11*. Journal of Contemporary Criminal Justice. Retrieved from https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1038.9462&rep=rep1&type=pdf

17. Hawdon et al. (2016, July 13). *Exposure to Online Hate in Four Nations: A Cross-National Consideration*. ResearchGate. Retrieved from https://www.researchgate.net/publication/303480309_Exposure_to_Online_Hate_in_Four_Nations_A_Cross-National_Consideration

18. Starosta A. (2019, February 15). *CBuilding NLP Classifiers Cheaply With Transfer Learning and Weak Supervision. Medium*. Retrieved from https://medium.com/sculpt/a-technique-for-building-nlp-classifiers-efficiently-with-transfer-learning-and-weak-supervision-a8e2f21ca9c8

19. Chetty N. & Alathur S. (2018, May 8). *Hate speech review in the context of online social networks*. Retrieved from https://www.sciencedirect.com/science/article/pii/S1359178917301064

20. Miró-Llinares F. & Rodriguez-Sala J.J. (2016, July). *Cyber Hate Speech on Twitter: Analyzing Disruptive Events from Social Media to Build a Violent Communication and Hate Speech taxonomy*. ResearchGate. Retrieved from https://www.researchgate.net/publication/308487177_Cyber_hate_speech_on_twitter_Analyzing_disruptive_events_from_social_media_to_build_a_violent_communication_and_hate_speech_taxonomy

21. Chen et al. (2015, June 8). *Crime prediction using Twitter sentiment and weather*. IEEE Xplore.  Retrieved from https://ieeexplore.ieee.org/abstract/document/7117012/authors#authors

22. Hashtagify. Search And Find The Best Twitter Hashtags. Available online: https://hashtagify.me/ (accessed on 15 March 2022).

23. Training Data for AI, ML with Human Empowered Automation. Cogit. Available online: https://www.cogitotech.com/about-us (accessed on 15 March 2022).

24. The HateMotiv Corpus. Kaggle. Available online: https://www.kaggle.com/datasets/nohaalnazzawi/the-hatemotiv-corpus (accessed on 3 October 2022).

\newpage

# Appendix A1. Twitter Data Collection

```{r}

# To run below codes for collecting tweets, first you'll need to create a .Renviron file by running
# set_bearer(), then store their bearer token in one line in the file like this
# TWITTER_BEARER = 'bearer token', close the file, and restart R session. 

# Run this code to use API credentials saved in the .Renviron file connects to the Twitter to get tweets data.
get_bearer()

# Function to get all tweets from year 2020 to 2022 by borough
get_tweets <- function(borough) {
  get_tweets <- get_all_tweets(
    query = "",
    n = 1000000,
    start_tweets = "2019-01-01T10:00:00Z",
    end_tweets = "2021-12-31T10:00:00Z",
    country = "US", 
    place = borough,
    lang = "en",
    page_n = 500
    
  )
  
  return(get_tweets)
}

# Function to select variables, transform date and coordinates,
# extract list-like columns, longitude, and latitude into new columns
extract_cols <- function(tweets, borough) {
  all_tweets <- cbind(tweets %>%
                        select(id,
                               created_at,
                               text,
                               source,
                               possibly_sensitive),
                      as.data.frame(tweets$geo$coordinates), 
                      as.data.frame(tweets$public_metrics))
  
  
  all_tweets <- all_tweets %>% 
    mutate(coordinates = as.character(coordinates))
  
  all_tweets <- all_tweets %>% 
    mutate(created_at = as.Date(created_at))
  
  all_tweets <- all_tweets %>% 
    mutate(longitude = parse_number(sub("[^-\\d]+", "", coordinates)))
  
  all_tweets <- all_tweets %>% 
    mutate(latitude = parse_number(sub("[^, \\d]+", "", coordinates)))
  
  all_tweets$borough <- borough
  
  return(all_tweets)
}

# Get historical tweets for each borough
m_twt_raw <- get_tweets("Manhattan, NY")
q_twt_raw <- get_tweets("Queens, NY")
k_twt_raw <- get_tweets("Brooklyn, NY")
x_twt_raw <- get_tweets("Bronx, NY")
s_twt_raw <- get_tweets("Staten Island, NY")

# Clean tweets data for each borough
m_twt_clean <- extract_cols(m_twt_raw, "MANHATTAN")
q_twt_clean <- extract_cols(q_twt_raw, "QUEENS")
k_twt_clean <- extract_cols(k_twt_raw, "BROOKLYN")
x_twt_clean <- extract_cols(x_twt_raw, "BRONX")
s_twt_clean <- extract_cols(s_twt_raw, "STATEN ISLAND")

# Combine borough data sets
tweets_data <- rbind(m_twt_clean,q_twt_clean,k_twt_clean,x_twt_clean,s_twt_clean)

# Read data from Github.
# As it takes time run above codes to collect NYC tweets data and also quota limitation per month to get # tweets data from Twitter, we uploaded the combined data we collect from running above codes to a Github # repo for convenient to read into R at any time.
tweets_data <- read.csv("https://raw.githubusercontent.com/SieSiongWong/DATA-698/master/Data/all_boroughs_2019_2021.csv", header=TRUE, sep=",")

```

\newpage

# Appendix A2. Crime Data Collection

```{r}

# Collect crime data from year 2019 to 2021.
crime_data <- read.socrata("https://data.cityofnewyork.us/resource/qgea-i56i.json?$select=cmplnt_fr_dt,addr_pct_cd,ofns_desc,pd_desc,susp_age_group,boro_nm,susp_race,susp_sex,latitude,longitude,vic_age_group,vic_race,vic_sex&$where=cmplnt_fr_dt between \'2019\' and \'2022\'")

```

\newpage

# Appendix B. Data Preprocessing

```{r}

# Filter hate related offensive corresponding description
hate_crime <- filter(crime_data, grepl('ASSAULT|HARRASSMENT', ofns_desc))

# Convert to date type
hate_crime$cmplnt_fr_dt <- as.Date(hate_crime$cmplnt_fr_dt)

# Remove meaningless characters and symbols in tweets text
tweets_data$text <- gsub("&amp","", tweets_data$text)
tweets_data$text <- gsub("(RT)((?:\\b\\w*@\\w+)+)","", tweets_data$text)
tweets_data$text <- gsub("^RT","", tweets_data$text)
tweets_data$text <- gsub("@\\w+","", tweets_data$text)
tweets_data$text <- gsub("[[:punct:]]","", tweets_data$text)
tweets_data$text <- gsub("[[:digit:]]+\\s","", tweets_data$text)
tweets_data$text <- gsub("http\\w+","", tweets_data$text)
tweets_data$text <- gsub("[ \t]{2,}"," ", tweets_data$text)

# Remove all non-ASCII characters 
tweets_data$text <- iconv(tweets_data$text, "UTF-8", "ASCII", sub="")

# Tokenize the text and see frequency of words.
tweets_data %>% 
  unnest_tokens(word, text)%>%
  anti_join(stop_words) %>%
  count(word, sort=TRUE) 

# We can see that words such as "ny, york, im, brooklyn, manhattan, bronx, nyc, queens, ave, 
# newyork" not pertaining to hatism topic, so we remove them.
tweets_data <- tweets_data %>% mutate(text=tolower(text))
tweets_data$text <- gsub("\\bny\\b|\\byork\\b|\\bim\\b|\\bbrooklyn\\b
                        |\\bmanhattan\\b|\\bbronx\\b|\\bqueens\\b|\\bnyc\\b
                        |\\bave\\b|\\bnewyork\\b|\\bstaten\\b|\\bisland\\b
                        |\\bnewyorkcity\\b|\\bjamaica\\b|\\bflushing\\b",
                        "", tweets_data$text)

```

\newpage

# Appendix C. Data Exploration

```{r}




```

\newpage

# Appendix D. Data Preparation

```{r}

# Get negative emotion score tweets
tweets_vector <- as.vector(tweets_data$text)
emotion_score <- get_sentiment(tweets_vector)
tweets_negative <- cbind(tweets_data, emotion_score) %>% filter(emotion_score < 0)

```

```{r}

# Select text and id column
tweets_corpus <- tweets_negative %>% 
  select(id, text) %>% 
  rename(doc_id = id) %>% 
  mutate(doc_id = as.character(doc_id))
  
# Create a corpus
tweets_corpus <- VCorpus(DataframeSource(tweets_corpus))
  
# Remove all punctuation from the corpus
tweets_corpus  <- tm_map(tweets_corpus, removePunctuation)

# Remove all English stopwords from the corpus.
tweets_corpus <- tm_map(tweets_corpus, removeWords, stopwords("en"))
tweets_corpus <- tm_map(tweets_corpus, removeWords, stopwords("SMART"))

# Remove all number from the corpus.
tweets_corpus <- tm_map(tweets_corpus, removeNumbers)

# Strip extra white spaces in the corpus.
tweets_corpus <- tm_map(tweets_corpus, stripWhitespace)

# Stem words in the corpus.
tweets_corpus <- tm_map(tweets_corpus, stemDocument)

# Build a document term matrix.
tweets_dtm <- DocumentTermMatrix(tweets_corpus)

# Increase memory in order to perform below codes
memory.limit(size=40000)

# Find the sum of words in each document and remove all docs without words.
row_total <- apply(tweets_dtm , 1, sum)
tweets_dtm_new   <- tweets_dtm[row_total> 0, ]

# Put the document in the format lda package required.
tweets_dtm_mtx <- as.matrix(tweets_dtm_new)

```

```{r}

# Function to get zip code from latitude and longitude
search_zip2 <- function(latitude, longitude) {
    
  return(if(is.na(latitude) | is.na(longitude)){''} 
         else {search_radius(latitude, longitude, radius = 0.7)$zipcode[1]})
  
}

# Use parallel processing method to run the function to get zip code
data$zipcode <- future_mapply(search_zip2,test2$latitude, test2$longitude)

```

\newpage

# Appendix E. Build Models

```{r}
```

\newpage

# Appendix F. Model Evaluation

```{r}
```


