---
title: |
  <center> DATA 698 </center>
  <center> Capstone Project </center>
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document:
    toc: yes
    toc_depth: 4
---

\begin{center}
\bigskip
\bigskip
\bigskip
Prepared for:\\
\medskip
Prof. Dr. Nasrin Khansari\\
\smallskip
City University of New York, School of Professional Studies\\
\bigskip
Prepared by:\\
\medskip
Sie Siong Wong\\ 
\smallskip
Mario Pena\\
\smallskip
Joseph Shi\\  
\end{center}

\pagebreak

```{R message=FALSE, warning=FALSE, echo=FALSE}
options(warn=-1)
if(!require('tidyverse')) (install.packages('tidyverse'))
if(!require('academictwitteR')) (install.packages('academictwitteR'))
if(!require('tidyr')) (install.packages('tidyr'))
if(!require('readr')) (install.packages('readr'))
if(!require('dplyr')) (install.packages('dplyr'))
if(!require('zipcodeR')) (install.packages('zipcodeR'))
if(!require('RSocrata')) (install.packages('RSocrata'))
if(!require('future.apply')) (install.packages('future.apply'))
if(!require('syuzhet')) (install.packages('syuzhet'))
if(!require('tm')) (install.packages('tm'))
if(!require('lda')) (install.packages('lda'))
if(!require('anytime')) (install.packages('anytime'))
if(!require('SnowballC')) (install.packages('SnowballC'))
if(!require('topicmodels')) (install.packages('topicmodels'))
if(!require('wordcloud')) (install.packages('wordcloud'))
if(!require('tidytext')) (install.packages('tidytext'))
```

\newpage

# Abstract

\newpage

# Introduction

Many of us spend several hours per week in social media platforms such as Facebook, Twitter, and Instagram to name a few. Although there are many advantages that social media provides e.g. serving as the fifth estate of power, a place to express opinions and such, it has also become a platform for someone to spread hate, cyberbullying, harassments and so on. Messages of hatred and spread of violence could have a high potential for influencing and motivating someone to commit a crime. According to CNN, hate crimes in New York City have increased 76% compared to last year. Many social media companies such as Facebook, have started to control the contents being posted by their users. Because there is a big concern in our society that offensive speech can result in more crimes and eventually become a serious threat to social, political, and cultural stability, we see the need to find a solution. 

Some may argue that the First Amendment allows individuals to express anything they want. Instead of limiting everyone’s freedom of speech openly in social media platforms, there are possible alternatives to deal with this issue. For example, a platform can allow users to turn on or off a switch to hide possible sensitive contents. In order to do this, we need some kind of solution that is able to identify inappropriate speech, tag them, and warn users that their post may not be visible to everyone due to containing sensitive language. 

We believe that offensive speech has a high potential for causing more violent crimes to happen in the city. To make our city a better place to live, we need to find a way not only to identify inappropriate speech in social media platforms and reduce the spread of such speech, but also when to deploy more law enforcement to patrol areas crowded with high numbers of offensive speech in the hope we interrupt crime prematurely. Our research hypothesis is that higher offensive tweets from an area have strong correlation to the number of crimes committed in that area and minority groups are mostly the target. 

The challenging part for our research is to classify the tweets metadata into offensive speech. Defining what is offensive speech such as hate speech can be hard because it’s constantly evolving and often dependent on context. Until today, artificial intelligence still struggles when it comes to identifying hate speech. But we’ve found that quite a few research scientists have tried different approaches to identifying offensive speech in social media text data. The more advanced techniques, deep learning methods such as gated recurrent unit (GRU), convolutional neural networks (CNN), gated convolutional recurrent - neural networks (GCR-NN), and combination of transfer learning and week supervision, are so far giving the best results compared to conventional classification approaches such as logistic regression, naive Bayes, decision tree, random forest, and gradient boosting.

There are many different types of hate speech that target different groups and individuals, and research has been done to differentiate and define them accordingly. Some approaches to the classification of hate speech from Tweeter use the hashtag as a variable for predicting violence and hate message from the tweet. While other approaches for classification of hate speech on social media may also include the development of neural language models. Additionally, there are algorithms that have been created to detect hate speech in digital microenvironments, which facilitate and reduce analysis tasks undergone by law enforcement agencies and service providers. We have also come across research that found there may not be a correlation between social media messages and crime, and others that consider “weather” to be an important environmental factor that affects the occurrence of criminal incidents. There have been many different approaches tried to find a link between social media posts and crime, all with varying results, and what makes this research so interesting is that we may yet find different results that may contribute to this solution.

\newpage

# Literature Review

The increase of using social media platforms such as Twitter and Facebook as a safe harbor to spread hate contents, and to cyberbully or harrass an individual or a minority group because of their identities such as race, religion, sexual orientation, etc., has promoted social disharmony in which may bring local crime rate to rise. ([\textcolor{cyan}{Williams et al., 2019}](https://academic.oup.com/bjc/article/60/1/93/5537169)) In this research article, a [\textcolor{cyan}{Weka}](https://www.weka.io/) tool was used to develop a machine learning classifier to annotate racism and religion and non-hateful tweets. Besides tweets and crime data, census data such as no qualifications, age, long-term unemployed, and black and minority ethnicity, were considered part of the study. Statistical models were built to study a temporal and spatial association. Random and fixed effects, Poisson regression models, and negative binomial models, which all results show consistent of positive association between hate speech in Twitter and offline racially and religiously discriminated crimes. Other research has also shown that online hate speech has a strong correlation with significant events such as terror attacks, political votes, etc ([\textcolor{cyan}{Hanes \& Machin, 2013}](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1038.9462&rep=rep1&type=pdf); [\textcolor{cyan}{Williams \& Burnap, 2015}](https://academic.oup.com/bjc/article/56/2/211/2462519)). A recent example of this was the Christchurch extreme right terror attacker’s post on 8chan. Although there is no direct causal link between online hate speech and offline hate crime, hate speech is still part of the cumulative process for a hate formula from social status, political context and geographical perspective that bring harm to the physical world. 

Nowadays, hate speech detection remains a big challenge for artificial intelligence. ([\textcolor{cyan}{Matsaki L., 2018}](https://www.wired.com/story/break-hate-speech-algorithm-try-love/)) Because the definition of hate speech is constantly evolving and often hidden within context, AI can be fooled easily. AI can be fooled by inserting typos, adding extra alphabets, and removing spaces. An example of altered text to evade AI detection would be something like this: “MartiansAreDisgustingAndShouldBeKilled love.” Humans can understand this message but the machine learning algorithms have trouble identifying it. Facebook CEO Mark Zuckerberg testified before congress in 2018 and mentioned he was optimistic that in 10 years AI would be able to identify hate speech more accurate. ([\textcolor{cyan}{Shead S., 2020}](https://www.cnbc.com/2020/11/19/facebook-says-ai-detects-94point7percent-of-hate-speech-removed-from-platform.html#:~:text=Facebook%20announced%20Thursday%20that%20artificial,and%20just%2024%25%20in%202017)) Only 24 percent of hate speech was able to be detected according to Facebook’s chief technology officer, Mike Schroepfer. Billions of users consume the Facebook product and platform, a cutting-edge machine technology to accurately spot hate speech is a must-have, to protect its users from exposure to harmful content. 

Many previous researchers have tried different machine learning approaches to best identify hate speech. ([\textcolor{cyan}{Lee et al., 2022}](https://www.researchgate.net/publication/357916429_Racism_Detection_by_Analyzing_Differential_Opinions_Through_Sentiment_Analysis_of_Tweets_Using_Stacked_Ensemble_GCR-NN_Model)) Stacked ensemble Gated Convolutional Recurrent- Neural Networks (GCR-NN), a deep learning approach was used to detect racist speech from a tweets dataset. Its 0.98 accuracy outperforms other conventional machine learning models such as Random Forest, K-Nearest Neighbors, SVM, etc. A large scale dataset of tweets related to racism from the world were collected, preprocessed to such detail as to remove stop words, annotated using the TextBlob into positive, negative and neutral score sentiments before performing Term Frequency - Inverse Document Frequency (TD-IDF), and Bag of Words (BoW) for machine learning models development. United States has the highest number of racist tweets, 50%, followed by United Kingdom, 31%. More than 53% of people age between 15-30 years old in the United States is exposed to online hate material ([\textcolor{cyan}{Hawdon et al., 2016}](https://www.researchgate.net/publication/303480309_Exposure_to_Online_Hate_in_Four_Nations_A_Cross-National_Consideration)). Both Logistic Regression and SVM performs better than other models using BoW features on average with a 0.97 accuracy score. For a fair comparison, few single deep learning models such as Gated Recurrent Unit (GRU), Long Short Term Memory (LSTM), Convolutional Neural Networks (CNN), and Recurrent Neural Networks (RNN), were also implemented and optimized through hyper parameter tuning. ([\textcolor{cyan}{Crabb et al., 2019}](https://towardsdatascience.com/classifying-hate-speech-an-overview-d307356b9eba); [\textcolor{cyan}{Starosta A., 2019}](https://medium.com/sculpt/a-technique-for-building-nlp-classifiers-efficiently-with-transfer-learning-and-weak-supervision-a8e2f21ca9c8)) Combination of Weak Supervision and Transfer Learning approach is useful for identifying which data lacks labeling. Weak supervision is a method for building a labeled training set from a large amount of unlabeled data. Transfer learning is a method where it reuses already existing pre-trained models for new tasks. It will use the training set created from weak supervision stage to build a new classifier model.

Research has found that there is a contradiction between freedom of speech and hate speech. Hate speech creates an environment that tests the limits of free speech, and it violates fundamental rights of a human being. On social networks, we can observe how other forms of violence such as terrorism, extremism and hate crimes, may each have their own space, victims and aggressors ([\textcolor{cyan}{Chetty \& Alathur, 2018}](https://www.sciencedirect.com/science/article/pii/S1359178917301064)). [\textcolor{cyan}{Miró-Llinares and Rodriguez-Sala (2016)}](https://www.researchgate.net/publication/308487177_Cyber_hate_speech_on_twitter_Analyzing_disruptive_events_from_social_media_to_build_a_violent_communication_and_hate_speech_taxonomy) describe the existence of many different types of hate speech that target different groups and individuals. Research has been done to differentiate and define each type accordingly. It is important to keep in mind classification as it will help us group Tweets with similar speech together in one category. Some of the approaches to the classification of hate speech from Tweeter used by [\textcolor{cyan}{Miró-Llinares and Rodriguez-Sala (2016)}](https://www.researchgate.net/publication/308487177_Cyber_hate_speech_on_twitter_Analyzing_disruptive_events_from_social_media_to_build_a_violent_communication_and_hate_speech_taxonomy) take into account the hashtags as a variable for predicting violence and hate message from the tweet. While some of their other approaches for classification of hate speech on social media also include the development of neural language models. It is also important to underline that the authors warn the development of classification algorithms may not allow for a deeper understanding of the different nature of violent communications. The recommendation they make is to pursue a thorough study of the categorization of different expressions that are evident in these types of messages.

The study conducted by [\textcolor{cyan}{Miró-Llinares et al. (2018)}](https://link.springer.com/article/10.1186/s40163-018-0089-1) focuses on designing an algorithm to detect hate speech in digital microenvironments. Its purpose is to facilitate and reduce analysis tasks undergone by law enforcement agencies and service providers. The algorithm used in this specific article uses machine learning classification techniques such as Random Forests. Furthermore, the study demonstrated that not all variables in the data relating to anonymity and visibility of users are applicable in distinguishing hate speech in tweets’ content, and that tweet metadata proved to be more efficient in the classification process than account metadata. Compared to similar studies that have applied different classification approaches, the results obtained by this study slightly outperform the others. The Random Forest model applied reached a F1-score of 0.92, highlighting the accuracy of the model on the dataset. Previous attempts from other studies have obtained F-measures of 0.77, 0.90 and 0.76 according to the literature in this specific study.

We have also found research that is centered on the idea that social media metadata is a valuable input in the analysis of opinions and sentiment. From activism to detecting road traffic, access to these data is essential in today’s comprehensive analyses. Using data from 18 Spanish-speaking Latin American countries, research found that similarly to mass media, social media suffers from a strong bias towards violent or sexual crimes. Simple models such as a linear regression were used in the research by [\textcolor{cyan}{Curiel et al. (2020)}](https://www.nature.com/articles/s41599-020-0430-7#Sec8) and found that countries with higher number of murders, murder rate and fear of crime are more likely to have crime-related tweets. However, it mainly represents the fears that people have of crime that may overemphasize certain types of crimes that are not as common as one would think. It was also found that there may not be a correlation at all between social media messages and crime, but rather demonstrate the reflection of the level of the fear of crime.

As explained by [\textcolor{cyan}{Chen et al. (2015)}](https://ieeexplore.ieee.org/abstract/document/7117012/authors#authors), it is possible for weather to also be used as a feature for modeling crime around Tweeter data. Their work is also focused on predicting crime in order to maximize the allocation of scarce police resources. Their paper noted the limitations of past studies, suggesting that weather is a significant factor and it has been proved there is a correlation between weather and criminal activity. It is thought that certain environmental factors such as weather, should be considered as it may affect the occurrence of criminal incidents. Such data containing information about theft density, Twitter data, weather and geolocation points, have been modeled using logistic regression with recommendations for future analysis using support vector machine ([\textcolor{cyan}{Chen et al., 2015}](https://ieeexplore.ieee.org/abstract/document/7117012/authors#authors)). More advanced techniques to predicting crime from Tweeter posts include Artificial Neural Networks approach that have achieved average accuracies of 0.903 on testing dataset and 0.933 on the training dataset as those demonstrated by [\textcolor{cyan}{Sandagiri et al. (2021)}](https://ieeexplore.ieee.org/document/9325485).

To develop and train a hate detection model, we’ll need a dataset with each record labeled with either hate or non-hate. This article ([\textcolor{cyan}{Alnazzawi, 2022}](https://www.mdpi.com/2306-5729/7/6/69)) developed a corpus which has hate related context, hate crime type, and the motivation behind the hate crime. This dataset is available in the [\textcolor{cyan}{Kaggle}](https://www.kaggle.com/datasets/nohaalnazzawi/the-hatemotiv-corpus) website and freely available to download. For our research, we could leverage this dataset in part of our annotation process to classify hate and non-hate tweets using the key words in the given hate related context. There were two steps in developing the dataset, corpus construction and annotation. The author used a Hashtag tracking tool [\textcolor{cyan}{“Hashtagify”}](https://hashtagify.me/) to search for hate related hashtags which were later to be used in the TweetsScraper tool to collect tweets related to hateful contents. Nine years (2010-2019) of tweets data related to these hashtags were collected. These hashtags list contain hate crime, racist, racism, Islamophobia, Islamophobic, sexism, disability, transgender, antisemitism, misogyny, and disabled. This hashtags list was found to be similar to what FBI used for the hate crime classification. For the annotation part, the author used the [\textcolor{cyan}{COGITO Tech (LLC)}](https://www.cogitotech.com/about-us) service to annotate each hate related tweets with 3 types of hate crime (physical assault, verbal abuse, incitement to hatred) and 5 types of motivation (racism, religion, disability, sexism, unknown) behind committing the crime. More than 60% of the 23,179 tweets, which hashtags’ are hate crime related, are made up of physical assault and most of these physical assault crimes were motivated because of different races and ethnicities.

\newpage

# Theory and Hypotheses

\newpage

# Data and Methods

There are two sets of data we collect for this study, crime data and tweets data. The date range for these data is from year January 2019 to December 2021. We may extend the data collection a year back if needed for our analysis. 

## Data Collection

Crime Data:

The crime data was collected from the NYC Open Data source ([\textcolor{cyan}{NYPD Complaint Data Historic}](https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i)) by using the available API. The read.socrata() function available from the "RSocrata" library was used to send query command through API to the site to get NYC crime data. Below are the variables and its values collected.

- cmplnt_fr_dt   : Date of incident occurred
- addr_pct_cd    : Precinct of incident occurred
- ofns_desc      : Offense description
- pd_desc        : Offense description (more granular)
- boro_nm        : Borough name
- susp_age_group : Suspect's age group
- susp_race      : Suspect's race
- susp_sex       : Suspect's sex
- latitude       : Latitude coordinate
- longitude      : Longitude coordinate
- vic_age_group  : Victim's age group
- vic_race       : Victim's race
- vic_sex        : Victim's sex

Tweets Data:

We applied for an academic research access developer account which has a higher tweets cap and got approved by ([\textcolor{cyan}{Twitter}](https://developer.twitter.com/en/docs/authentication/guides/log-in-with-twitter) for our research purpose to collect tweets data through API as well. The get_all_tweets() function available from "academictwitteR" library was used to query NYC tweets data. From the data return, we select below variables which will be used for model building.

- id                 : Unique identification for each tweet
- created_at         : Date the tweets created
- text               : Text written by user              
- source             : Source used by user to tweet            
- possibly_sensitive : True/False content is sensitive
- type               : Type of coordinates              
- coordinates        : Longitude and latitude coordinates       
- retweet_count      : Count of retweet     
- reply_count        : Count of reply to the tweet       
- like_count         : Count of like to the tweet        
- quote_count        : Count of retweet with comments       
- longitude          : Longitude coordinate         
- latitude           : Latitude coordinate          
- borough            : Borough name       

## Data Analysis

We’ll use a sentiment analysis approach to annotate tweets into positive, negative, and neutral sentiments. Then, we further classify all negative sentiment tweets into hate and non-hate speech by using either topic modeling or refer to a collection of defined offensive speech. All identified offensive tweets will then be mapped to the crimes reported by using date and coordinates for correlation and time series analysis.

For performance comparison, several well-known classification machine learning models such as random forest, KNN, SVM, will be implemented using the optimized parameters and a deep learning model. Recurrent neural networks (RNN) will also be considered. Below is the architecture of the proposed methodology.

$$\\[0.5in]$$
![Architecture of the Proposed Methodology]("C:\\Users\\wongs34\\Documents\\School\\DATA 698\\Proposal\\Architecture of the Proposed Methodology.png")

\newpage

# Results

\newpage

# Discussion

\newpage

# Conclusion

\newpage

# References

1. Kshirsagar V. (2019, December 24). *Detecting Hate tweets — Twitter Sentiment Analysis*. Towards Data Science. Retrieved from https://towardsdatascience.com/detecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6

2. Crabb et al. (2019, May 28). *Classifying Hate Speech: an overview*. Towards Data Science. Retrieved from https://towardsdatascience.com/classifying-hate-speech-an-overview-d307356b9eba

3. Pang, G. (2022, March 4). *Deep Learning for Hate Speech Detection: A Large-scale Empirical Evaluation*. Towards Data Science. Retrieved from https://towardsdatascience.com/deep-learning-for-hate-speech-detection-a-large-scale-empirical-evaluation-92831ded6bb6

3. Kim, H. (2022). *Sentiment Analysis: Limits and Progress of the Syuzhet Package and Its Lexicons*. Texas A&M University. Retrieved from http://www.digitalhumanities.org/dhq/vol/16/2/000612/000612.html

4. Williams et al. (2019, July 23). *Hate in the Machine: Anti-Black and Anti-Muslim Social Media Posts as Predictors of Offline Racially and Religiously Aggravated Crime*. The British Journal of Criminology. Retrieved from https://academic.oup.com/bjc/article/60/1/93/5537169

5. Lee et al. (2022, January). *Racism Detection by Analyzing Differential Opinions Through Sentiment Analysis of Tweets Using Stacked Ensemble GCR-NN Model*. ResearchGate. Retrieved from https://www.researchgate.net/publication/357916429_Racism_Detection_by_Analyzing_Differential_Opinions_Through_Sentiment_Analysis_of_Tweets_Using_Stacked_Ensemble_GCR-NN_Model

6. Matsaki L. (2018, September 26). *To Break a Hate-Speech Detection Algorithm, Try 'Love'*. Wired.  Retrieved from https://www.wired.com/story/break-hate-speech-algorithm-try-love/

7. Rizwan et al. (2020, January). *Hate-Speech and Offensive Language Detection in Roman Urdu*. ACL Anthology. Retrieved from https://aclanthology.org/2020.emnlp-main.197.pdf

8. Miró-Llinares et al. (2018, November 15). *Hate is in the air! But where? Introducing an algorithm to detect hate speech in digital microenvironments*. Springer Link. Retrieved from https://link.springer.com/article/10.1186/s40163-018-0089-1

9. Curiel et al. (2020, April 02). *Crime and its fear in social media*. Nature. Retrieved from https://www.nature.com/articles/s41599-020-0430-7#Sec8

10. Sandagiri et al. (2021, January 19). *Detecting Crime Related Twitter Posts using Artificial Neural Networks based Approach*. IEEE Xplore. Retrieved from https://ieeexplore.ieee.org/document/9325485

11. Kumar, A. (2022, March 20). *Hate Speech Detection Using Machine Learning*. Vitalflux. Retrieved from https://vitalflux.com/hate-speech-detection-using-machine-learning/#:~:text=The%20techniques%20for%20detecting%20hate,to%20find%20patterns%20in%20data.

12. Alnazzawi, N. (2022, May 24). *Using Twitter to Detect Hate Crimes and Their Motivations: The HateMotiv Corpus*. MDPI. Retrieved from https://www.mdpi.com/2306-5729/7/6/69

13. Kocon et al. (2021, June 03). *Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach*. ScienceDirect. Retrieved from https://www.sciencedirect.com/science/article/pii/S0306457321001333

14. Shead, S. (2020, November 19). *Facebook claims A.I. now detects 94.7% of the hate speech that gets removed from its platform*. CNBC. Retrieved from https://www.cnbc.com/2020/11/19/facebook-says-ai-detects-94point7percent-of-hate-speech-removed-from-platform.html#:  
~:text=Facebook%20announced%20Thursday%20that%20artificial,and%20just%2024%25%20in%202017.

15. Williams, M. & Burnap, P. (2015, June 25 ). *Cyberhate on Social Media in the Aftermath of Woolwich: A Case Study in Computational Criminology and Big Data*. British Journal of Criminology. Retrieved from https://academic.oup.com/bjc/article/56/2/211/2462519

16. Hanes, E. & Machin, S. (2013, September). *Hate Crime in the Wake of Terror Attacks: Evidence from 7/7 and 9/11*. Journal of Contemporary Criminal Justice. Retrieved from https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1038.9462&rep=rep1&type=pdf

17. Hawdon et al. (2016, July 13). *Exposure to Online Hate in Four Nations: A Cross-National Consideration*. ResearchGate. Retrieved from https://www.researchgate.net/publication/303480309_Exposure_to_Online_Hate_in_Four_Nations_A_Cross-National_Consideration

18. Starosta A. (2019, February 15). *CBuilding NLP Classifiers Cheaply With Transfer Learning and Weak Supervision. Medium*. Retrieved from https://medium.com/sculpt/a-technique-for-building-nlp-classifiers-efficiently-with-transfer-learning-and-weak-supervision-a8e2f21ca9c8

19. Chetty N. & Alathur S. (2018, May 8). *Hate speech review in the context of online social networks*. Retrieved from https://www.sciencedirect.com/science/article/pii/S1359178917301064

20. Miró-Llinares F. & Rodriguez-Sala J.J. (2016, July). *Cyber Hate Speech on Twitter: Analyzing Disruptive Events from Social Media to Build a Violent Communication and Hate Speech taxonomy*. ResearchGate. Retrieved from https://www.researchgate.net/publication/308487177_Cyber_hate_speech_on_twitter_Analyzing_disruptive_events_from_social_media_to_build_a_violent_communication_and_hate_speech_taxonomy

21. Chen et al. (2015, June 8). *Crime prediction using Twitter sentiment and weather*. IEEE Xplore.  Retrieved from https://ieeexplore.ieee.org/abstract/document/7117012/authors#authors

22. Hashtagify. Search And Find The Best Twitter Hashtags. Available online: https://hashtagify.me/ (accessed on 15 March 2022).

23. Training Data for AI, ML with Human Empowered Automation. Cogit. Available online: https://www.cogitotech.com/about-us (accessed on 15 March 2022).

24. The HateMotiv Corpus. Kaggle. Available online: https://www.kaggle.com/datasets/nohaalnazzawi/the-hatemotiv-corpus (accessed on 3 October 2022).

25. NYPD Complaint Data Historic. NYC Open Data. Available online: https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i (accessed on 17 October 2022).

\newpage

# Appendix A1. Twitter Data Collection

```{r}

# To run below codes for collecting tweets, first you'll need to create a .Renviron file by running
# set_bearer(), then store their bearer token in one line in the file like this
# TWITTER_BEARER = 'bearer token', close the file, and restart R session. 

# Run this code to use API credentials saved in the .Renviron file connects to the Twitter to get tweets data.
get_bearer()

# Function to get all tweets from year 2020 to 2022 by borough
get_tweets <- function(borough) {
  get_tweets <- get_all_tweets(
    query = c("#hate crime", "#racist", "#racism", "#Islamophobia", "#Islamophobic", "#sexism",
            "#disability", "#transgender", "#antisemitism", "#misogyny", "#disabled", "slurs",
            "violent", "murder", "xenophobic", "nigga", "threat", "punching", "harrass", "assault", 
            "black babies", "islam", "nazi", "genocide", "fuck", "shit", "discrimination", "bitch", 
            "verbal abuse", "black babies", "violence", "white genocide", "graffiti", "explosion", 
            "enslaved", "attack", "bomb", "harrassment", "killing minorities", "monsters", "black man", 
            "killer", "shot dead", "hijab", "insult", "discriminate", "intimidation", "sexual assault",
            "black folks", "white supremacist", "homophobic", "burning a LGBT", "hatred", 
            "muslim", "stabbing", "harrasing", "smashed", "punched", "choked", "knocking", "rape", 
            "burned to death", "bastard", "stripped", "interracial", "slavery", "bomb", "torture", 
            "abuse", "fucking", "slaughter", "brutally", "bully", "go back to your"),
    n = 1000000,
    start_tweets = "2019-01-01T10:00:00Z",
    end_tweets = "2021-12-31T10:00:00Z",
    country = "US", 
    place = borough,
    lang = "en",
    page_n = 500,
    point_radius = c(-73.989121, 40.702944, 18)
    
  )
  
  return(get_tweets)
}

# Function to select variables, transform date and coordinates,
# extract list-like columns, longitude, and latitude into new columns
extract_cols <- function(tweets, borough) {
  all_tweets <- cbind(tweets %>%
                        select(id,
                               created_at,
                               text,
                               source,
                               possibly_sensitive),
                      as.data.frame(tweets$geo$coordinates), 
                      as.data.frame(tweets$public_metrics))
  
  
  all_tweets <- all_tweets %>% 
    mutate(coordinates = as.character(coordinates))
  
  all_tweets <- all_tweets %>% 
    mutate(created_at = as.Date(created_at))
  
  all_tweets <- all_tweets %>% 
    mutate(longitude = parse_number(sub("[^-\\d]+", "", coordinates)))
  
  all_tweets <- all_tweets %>% 
    mutate(latitude = parse_number(sub("[^, \\d]+", "", coordinates)))
  
  all_tweets$borough <- borough
  
  return(all_tweets)
}

# Get historical tweets for each borough
m_twt_raw <- get_tweets("Manhattan")
q_twt_raw <- get_tweets("Queens")
k_twt_raw <- get_tweets("Brooklyn")
x_twt_raw <- get_tweets("Bronx")
s_twt_raw <- get_tweets("Staten Island")

# Clean tweets data for each borough
m_twt_clean <- extract_cols(m_twt_raw, "MANHATTAN")
q_twt_clean <- extract_cols(q_twt_raw, "QUEENS")
k_twt_clean <- extract_cols(k_twt_raw, "BROOKLYN")
x_twt_clean <- extract_cols(x_twt_raw, "BRONX")
s_twt_clean <- extract_cols(s_twt_raw, "STATEN ISLAND")

# Read data from Github.
# As it takes time run above codes to collect NYC tweets data and also quota limitation per month to get # tweets data from Twitter, we uploaded the each borough data we collect from running above codes to a 
# Github repo for convenient to read into R at any time.

# Github path
github <- "https://raw.githubusercontent.com/SieSiongWong/DATA-698/master/Data/"
m_twt <- read.csv(paste0(github,"manhattan_2019_2021.csv"), header=TRUE, sep=",")
q_twt <- read.csv(paste0(github,"queens_2019_2021.csv"), header=TRUE, sep=",")
k_twt <- read.csv(paste0(github,"brooklyn_2019_2021.csv"), header=TRUE, sep=",")
x_twt <- read.csv(paste0(github,"bronx_2019_2021.csv"), header=TRUE, sep=",")
s_twt <- read.csv(paste0(github,"staten_island_2019_2021.csv"), header=TRUE, sep=",")

# Combine borough data sets
tweets_data <- rbind(m_twt,q_twt,k_twt,x_twt,s_twt)

```

\newpage

# Appendix A2. Crime Data Collection

```{r}

# Collect crime data from year 2019 to 2021.
crime_data <- read.socrata("https://data.cityofnewyork.us/resource/qgea-i56i.json?$select=cmplnt_fr_dt,addr_pct_cd,ofns_desc,pd_desc,susp_age_group,boro_nm,susp_race,susp_sex,latitude,longitude,vic_age_group,vic_race,vic_sex&$where=cmplnt_fr_dt between \'2019\' and \'2022\'")

```

\newpage

# Appendix B. Data Preprocessing

```{r}

# Filter hate related offensive corresponding description
hate_crime <- filter(crime_data, grepl('ASSAULT|HARRASSMENT', ofns_desc))

# Convert to date type
hate_crime$cmplnt_fr_dt <- as.Date(hate_crime$cmplnt_fr_dt)

# Remove meaningless characters and symbols in tweets text
tweets_data$text <- gsub("&amp","", tweets_data$text)
tweets_data$text <- gsub("<[^>]+>","", tweets_data$text)
tweets_data$text <- gsub("#\\w+","", tweets_data$text)
tweets_data$text <- gsub("@\\w+","", tweets_data$text)
tweets_data$text <- gsub("[[:punct:]]","", tweets_data$text)
tweets_data$text <- gsub("http\\w+","", tweets_data$text)
tweets_data$text <- gsub("[ \t]{2,}"," ", tweets_data$text)

# Remove all non-ASCII characters 
tweets_data$text <- iconv(tweets_data$text, "UTF-8", "ASCII", sub="")

# Tokenize the text and see frequency of words.
tweets_data %>% 
  unnest_tokens(word, text)%>%
  anti_join(stop_words) %>%
  count(word, sort=TRUE) 

# We can see that words such as "ny, york, im, brooklyn, manhattan, bronx, nyc, queens, ave, 
# newyork" not pertaining to hatism topic, so we remove them.
tweets_data <- tweets_data %>% mutate(text=tolower(text))
tweets_data$text <- gsub("\\bny\\b|\\byork\\b|\\bim\\b|\\bbrooklyn\\b
                        |\\bmanhattan\\b|\\bbronx\\b|\\bqueens\\b|\\bnyc\\b
                        |\\bave\\b|\\bnewyork\\b|\\bstaten\\b|\\bisland\\b
                        |\\bnewyorkcity\\b|\\bjamaica\\b|\\bflushing\\b",
                        "", tweets_data$text)

```

\newpage

# Appendix C. Data Exploration

```{r}




```

\newpage

# Appendix D. Data Preparation

```{r}

# Get negative emotion score tweets
tweets_vector <- as.vector(tweets_data$text)
emotion_score <- get_sentiment(tweets_vector)
tweets_negative <- cbind(tweets_data, emotion_score) %>% filter(emotion_score < 0)

```

```{r}

# Select text and id column
tweets_corpus <- tweets_negative %>% 
  select(id, text) %>% 
  rename(doc_id = id) %>% 
  mutate(doc_id = as.character(doc_id))
  
# Create a corpus
tweets_corpus <- VCorpus(DataframeSource(tweets_corpus))
  
# Remove all punctuation from the corpus
tweets_corpus  <- tm_map(tweets_corpus, removePunctuation)

# Remove all English stopwords from the corpus.
tweets_corpus <- tm_map(tweets_corpus, removeWords, stopwords("en"))
tweets_corpus <- tm_map(tweets_corpus, removeWords, stopwords("SMART"))

# Remove all number from the corpus.
tweets_corpus <- tm_map(tweets_corpus, removeNumbers)

# Strip extra white spaces in the corpus.
tweets_corpus <- tm_map(tweets_corpus, stripWhitespace)

# Stem words in the corpus.
tweets_corpus <- tm_map(tweets_corpus, stemDocument)

# Build a document term matrix.
tweets_dtm <- DocumentTermMatrix(tweets_corpus)

# Increase memory in order to perform below codes
memory.limit(size=40000)

# Find the sum of words in each document and remove all docs without words.
row_total <- apply(tweets_dtm , 1, sum)
tweets_dtm_new   <- tweets_dtm[row_total> 0, ]

# Put the document in the format lda package required.
tweets_dtm_mtx <- as.matrix(tweets_dtm_new)

# Create a LDA model with Gibbs method for 30 topics.
tweets_LDA <- LDA(tweets_dtm_mtx, 25, method="Gibbs", control = list(seed = 123))

# Top 30 words per topic.
terms(tweets_LDA, 30)

```

```{r}

# Per-topic-per-word probabilities.
tweetsLDA.topicword.prob <- tidy(tweets_LDA, matrix="beta")

# Find the 10 terms that are most common within each topic.
tweetsLDA.topterms <- tweetsLDA.topicword.prob %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Plot per-topic-per-word probabilities for topic #26.
tweetsLDA.topterms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  filter(topic==9) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()

# Classify the selected topic #26 per document.
tweetsLDA.class <- data.frame(topics(tweets_LDA))
tweetsLDA.class <- cbind(tweetsLDA.class, 1:nrow(tweetsLDA.class))
colnames(tweetsLDA.class)[ncol(tweetsLDA.class)] <-'doc_id'
tweetsLDA.class <- tweetsLDA.class %>% filter(topics.tweets_LDA.==9)

# Inner join selected classified topic with original dataframe.
test_data$doc_id <- as.character(tweets_data$X)
tweetsLDA.class$doc_id <- as.character(tweetsLDA.class$doc_id)
tweets.final <- inner_join(tweetsLDA.class, test_data)
head(tweets.final)

write.csv(tweets.final,"C:\\Users\\wongs34\\Downloads\\test3.csv", row.names = FALSE)
```


```{r}

# Function to get zip code from latitude and longitude
search_zip2 <- function(latitude, longitude) {
    
  return(if(is.na(latitude) | is.na(longitude)){''} 
         else {search_radius(latitude, longitude, radius = 0.7)$zipcode[1]})
  
}

# Use parallel processing method to run the function to get zip code
data$zipcode <- future_mapply(search_zip2,test2$latitude, test2$longitude)

```

\newpage

# Appendix E. Build Models

```{r}
```

\newpage

# Appendix F. Model Evaluation

```{r}
```


